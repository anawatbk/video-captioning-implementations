{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path configuration\n",
    "LABELS_PATH = '../data/train_val_annotation/train_val_videodatainfo.json'\n",
    "DATA_PATH = '../data/train_val_features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file\n",
    "f = open (LABELS_PATH, \"r\")\n",
    "  # Reading from file\n",
    "data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 9,\n",
       " 'url': 'https://www.youtube.com/watch?v=9lZi22qLlEo',\n",
       " 'video_id': 'video0',\n",
       " 'start time': 137.72,\n",
       " 'end time': 149.44,\n",
       " 'split': 'train',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['videos'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomly select sentence\n",
    "#label_df = pd.DataFrame(data['sentences'])\n",
    "#label_final_df = label_df.groupby('video_id')['sen_id'].unique().apply(lambda x: x[np.random.randint(0,20)]).to_frame().reset_index()\n",
    "#label_final_df['video_id'].nunique()\n",
    "#label_final_df = label_final_df.join(label_df[['sen_id', 'caption']].set_index('sen_id'), on='sen_id')\n",
    "#label_final_df.to_csv('../data/label_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_final_df = pd.read_csv('../data/label_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create embedding matrix from google news word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en_core_web_sm', disable = ['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "# embedding\n",
    "import gensim.downloader\n",
    "\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "glove_emb = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = label_final_df['caption'].tolist()#.astype('unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = Counter()\n",
    "try:\n",
    "    for doc in nlp.pipe(all_sent):\n",
    "        for word in doc:\n",
    "            #print(word)\n",
    "            wc[str(word)] += 1\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(doc,'\\nword:', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding matrix\n",
    "# initialization\n",
    "EMBEDDING_SIZE = 300\n",
    "embedding = np.zeros((len(wc)+4, 300)) # +4 for start, end, unk, padding\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "\n",
    "word2idx['<PAD>'] = 0\n",
    "idx2word[0] = '<PAD>'\n",
    "embedding[0] = np.random.rand(300)*2 - 1\n",
    "\n",
    "word2idx['<START>'] = 1\n",
    "idx2word[1] = '<START>'\n",
    "embedding[1] = np.random.rand(300)*2 - 1\n",
    "\n",
    "word2idx['<END>'] = 2\n",
    "idx2word[2] = '<END>'\n",
    "embedding[2] = np.random.rand(300)*2 - 1\n",
    "\n",
    "word2idx['<UNK>'] = 3\n",
    "idx2word[3] = '<UNK>'\n",
    "embedding[3] = np.random.rand(300)*2 - 1\n",
    "\n",
    "count = 0\n",
    "for word, _ in wc.most_common():\n",
    "    wid = len(word2idx)\n",
    "    word2idx[word] = wid\n",
    "    idx2word[wid] = word\n",
    "    if word in glove_emb:\n",
    "        embedding[wid] = glove_emb.get_vector(word)\n",
    "    else:\n",
    "        embedding[wid] = np.random.rand(300)*2 - 1 # random initialisation (-1, 1)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 words are not in google news werd2vec\n"
     ]
    }
   ],
   "source": [
    "print(f'{count} words are not in google news werd2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../model/embedding.npy', embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../model/word2idx.pkl\",\"wb\") as f:\n",
    "    pickle.dump(word2idx, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model/idx2word.pkl\",\"wb\") as f:\n",
    "    pickle.dump(idx2word, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Dataset Class for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSRVTT(Dataset):\n",
    "    def __init__(self, df, word2idx, DATA_PATH):\n",
    "        super(MSRVTT, self).__init__()\n",
    "        self.df = df\n",
    "        self.path = DATA_PATH\n",
    "        self.word2idx = word2idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        vid = row['video_id']\n",
    "        filename = self.path + f'{vid}-feature.pt5'\n",
    "        x = torch.load(filename)\n",
    "        sentence_emb = [self.word2idx.get(word, self.word2idx['<UNK>']) for word in row['caption'].split(' ')]\n",
    "        y = torch.zeros(len(sentence_emb)+2)\n",
    "        y[0], y[-1] = self.word2idx['<START>'], self.word2idx['<END>']\n",
    "        y[1:-1] = torch.tensor(sentence_emb)\n",
    "        #true_sentence = row['caption']\n",
    "        y = F.pad(y, pad=(0, 20 - y.shape[0]))\n",
    "        x = F.pad(x, pad=(0, 0, 40-x.shape[0], 0))\n",
    "        return x, y.long()#, true_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MSRVTT(label_final_df, word2idx, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0396, 0.4085, 0.5028,  ..., 0.6331, 0.1015, 0.0470],\n",
       "         [0.1039, 0.4748, 0.6943,  ..., 0.5652, 0.6987, 0.2298],\n",
       "         [0.6233, 0.3887, 0.9117,  ..., 0.8732, 0.4357, 0.4482]]),\n",
       " tensor([  1,  42,  13, 204,  23, 697,  31,   4, 261, 481,   2,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0]))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_size = []\n",
    "sents_length = []\n",
    "for data in ds_iter:\n",
    "    frames_size.append(data[0].shape[0])\n",
    "    sents_length.append(len(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frames length distribution\n",
    "plt.hist(frames_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sentence length distribution\n",
    "plt.hist(sents_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6519 491\n"
     ]
    }
   ],
   "source": [
    "# split train/test\n",
    "train_proportion = 0.93\n",
    "train_size = int(train_proportion * len(ds))\n",
    "validation_size = len(ds) - train_size\n",
    "print(train_size, validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, validation_ds = random_split(ds, [train_size, validation_size])\n",
    "# dataloaders\n",
    "train_dl = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "valid_dl = DataLoader(validation_ds, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 800])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "cnn = nn.Conv1d(40, 10, 5, stride=2)\n",
    "fc = nn.Linear(5110, 800)\n",
    "x = F.max_pool1d(F.relu(cnn(x)), 2)\n",
    "x = torch.flatten(x, 1)\n",
    "x = x.unsqueeze(0)\n",
    "x = fc(x)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence Model (Encoder-Decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While image description handles a variable length output sequence of words, video description also has to handle a variable length input sequence of frames. Related approaches to video description have resolved variable length input by holistic video representations [29, 28, 11], pooling over frames [39], or sub-sampling on a fixed number of input frames [43]. In contrast, in this work we propose a sequence to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import resnet18, resnet101\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Conv1d(40, 10, 5, stride=2)\n",
    "        self.fc = nn.Linear(5110, hidden_dim)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool1d(F.relu(self.cnn(x)), 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    Decode Hidden State from Encoder to sentence (sequence of texts)\n",
    "    \n",
    "    note: batch_first=True does not apply to hidden or cell states\n",
    "    '''\n",
    "    def __init__(self, weights, emb_dim, hidden_dim, out_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        # layers\n",
    "        self.emb = nn.Embedding.from_pretrained(torch.tensor(weights), padding_idx=0, freeze=False)\n",
    "        self.rnn = nn.GRU(emb_dim + hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc_out = nn.Linear(emb_dim + hidden_dim * 2, out_dim)\n",
    "                \n",
    "    def forward(self, word_input, encoded_context, hidden):\n",
    "        '''\n",
    "        word_input: (batch_size)\n",
    "        encoded_context: (1, batch_size, hidden_dim)\n",
    "        hidden: (1, batch_size, hidden_dim)\n",
    "        '''\n",
    "        # 1 word at a time\n",
    "    \n",
    "        word_input = self.emb(word_input) # dim (batch, emb_dim)\n",
    "        emb_input = torch.cat([word_input, encoded_context.squeeze(0)], dim=1)\n",
    "        output, hidden = self.rnn(emb_input.unsqueeze(1).float(), hidden)\n",
    "        prediction = self.fc_out(torch.cat([word_input, encoded_context.squeeze(0), hidden.squeeze(0)], dim=1).float())\n",
    "        return prediction, hidden \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, x, y, teacher_forcing_ratio=0.8):\n",
    "        '''\n",
    "        x: PackedSequence\n",
    "        y: (batch_size, sentence_len(padded))\n",
    "        hidden: (1, batch_size, hidden_dim)\n",
    "        '''\n",
    "        batch_size = y.size(0)\n",
    "        sentence_len = y.size(1)\n",
    "        vocab_size = self.decoder.out_dim\n",
    "        \n",
    "        ##############\n",
    "        # Initialize #\n",
    "        ##############\n",
    "        # tensor for final outputs\n",
    "        outputs = torch.zeros(batch_size, sentence_len, vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is the context\n",
    "        encoded_context = self.encoder(x) # (1, batch_size, hidden_dim)\n",
    "        # first hidden state \n",
    "        hidden = encoded_context # (1, batch_size, hidden_dim)\n",
    "        # first input '<START>'\n",
    "        word_input = y[:, 0] # (batch_size)\n",
    "        for t in range(1, sentence_len):\n",
    "            #insert input token embedding, previous hidden state and the context state\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(word_input, encoded_context, hidden)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[:, t, :] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = np.random.rand() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) # dim: (batch_size)\n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            word_input = y[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_VOCAB = len(word2idx)\n",
    "EMB_DIM = 300\n",
    "INPUT_DIM = 2048 # resnet50 fc dim\n",
    "HIDDEN_DIM = 800\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = Encoder(INPUT_DIM, HIDDEN_DIM)\n",
    "decoder = Decoder(embedding, EMB_DIM, HIDDEN_DIM, N_VOCAB)\n",
    "model = Seq2Seq(encoder, decoder, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight initialization with N(0, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.cnn.weight torch.Size([10, 40, 5])\n",
      "encoder.cnn.bias torch.Size([10])\n",
      "encoder.fc.weight torch.Size([800, 5110])\n",
      "encoder.fc.bias torch.Size([800])\n",
      "decoder.rnn.weight_ih_l0 torch.Size([2400, 1100])\n",
      "decoder.rnn.weight_hh_l0 torch.Size([2400, 800])\n",
      "decoder.rnn.bias_ih_l0 torch.Size([2400])\n",
      "decoder.rnn.bias_hh_l0 torch.Size([2400])\n",
      "decoder.fc_out.weight torch.Size([6157, 1900])\n",
      "decoder.fc_out.bias torch.Size([6157])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name != 'decoder.emb.weight':\n",
    "        print(name, param.shape)\n",
    "        nn.init.normal_(param.data, mean=0, std=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.CrossEntropyLoss(ignore_index=0)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, threshold=0.001, threshold_mode='rel', min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, lossFun, backwards=True, print_loss=False):\n",
    "    \n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(tqdm(dataloader)):\n",
    "        \n",
    "        out = model(x, y)\n",
    "        out = out.view(-1, 6157)\n",
    "        y = y.view(-1)\n",
    "        loss = lossFun(out, y)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        if i % 50 == 0:\n",
    "            print(f'Batch loss: {loss.item()}')\n",
    "        if backwards == True:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    if print_loss == True:\n",
    "        print(avg_loss)\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, lossFun):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for x, y in tqdm(dataloader):\n",
    "\n",
    "            out = model(x, y)\n",
    "            out = out.view(-1, 6157)\n",
    "            y = y.view(-1)\n",
    "            loss = lossFun(out, y)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Batch loss: 54.196502685546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 50/815 [01:10<17:35,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.402602672576904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 100/815 [02:17<16:06,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.826196670532227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 150/815 [03:25<15:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.811034679412842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 200/815 [04:31<13:45,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 6.241280555725098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 250/815 [05:39<12:39,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.855584621429443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 300/815 [06:46<11:41,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.643556118011475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 350/815 [07:54<10:31,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.169535160064697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 400/815 [09:02<09:25,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.052654266357422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 450/815 [10:10<08:15,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.4008097648620605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 500/815 [11:18<07:08,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.242780685424805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 550/815 [12:26<06:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 6.48536491394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 600/815 [13:34<04:53,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.628023624420166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 650/815 [14:42<03:44,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.421504020690918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 700/815 [15:51<02:38,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 6.203864097595215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 750/815 [17:01<01:37,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.536386966705322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 800/815 [18:09<00:20,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.317307949066162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [18:30<00:00,  1.36s/it]\n",
      "  0%|          | 1/246 [00:00<00:39,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  6.074268651154875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:37<00:00,  6.52it/s]\n",
      "  0%|          | 0/815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss:  5.127470451641858\n",
      "Epoch:  1\n",
      "Batch loss: 4.8193864822387695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 50/815 [01:07<17:12,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.952256202697754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 100/815 [02:14<15:51,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.747147560119629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 150/815 [03:21<14:59,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.694643974304199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 200/815 [04:28<13:41,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.7956926822662354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 250/815 [05:35<12:38,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.10654878616333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 300/815 [06:42<11:35,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.94657564163208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 350/815 [07:50<10:24,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.755015850067139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 400/815 [08:57<09:15,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.091688632965088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 450/815 [10:05<08:15,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.514028549194336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 500/815 [11:11<06:42,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.788376808166504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 550/815 [12:15<05:43,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.326396465301514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 600/815 [13:21<04:43,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.588245868682861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 650/815 [14:27<03:38,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.420936107635498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 700/815 [15:33<02:33,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.163949012756348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 750/815 [16:40<01:25,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.2839813232421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 800/815 [17:46<00:19,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.5531721115112305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [18:06<00:00,  1.33s/it]\n",
      "  0%|          | 1/246 [00:00<00:39,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  4.689446207350748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:37<00:00,  6.49it/s]\n",
      "  0%|          | 0/815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss:  5.006125212684879\n",
      "Epoch:  2\n",
      "Batch loss: 4.04577112197876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 50/815 [01:05<16:55,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.8613388538360596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 100/815 [02:11<15:23,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.8414463996887207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 150/815 [03:16<14:29,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.8356118202209473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 200/815 [04:21<13:34,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.842285633087158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 250/815 [05:27<12:18,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.52432918548584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 300/815 [06:32<11:14,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.6563403606414795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 350/815 [07:39<10:13,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.565664291381836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 400/815 [08:44<09:05,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.272218227386475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 450/815 [09:50<07:57,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 5.039133548736572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 500/815 [10:56<06:52,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.9043829441070557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 550/815 [12:02<05:50,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.5605411529541016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 600/815 [13:08<04:43,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.4173712730407715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 650/815 [14:14<03:37,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.417525291442871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 700/815 [15:20<02:32,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.7460622787475586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 750/815 [16:27<01:25,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.538760662078857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 800/815 [17:33<00:19,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.034374713897705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [17:52<00:00,  1.32s/it]\n",
      "  0%|          | 1/246 [00:00<00:39,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  4.091585732969039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:38<00:00,  6.47it/s]\n",
      "  0%|          | 0/815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss:  5.1024510308009825\n",
      "Epoch:  3\n",
      "Batch loss: 3.845869302749634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 50/815 [01:05<16:38,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.174389362335205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 100/815 [02:10<15:26,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.014134883880615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 150/815 [03:15<14:12,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 2.8342530727386475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 200/815 [04:19<13:09,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.2557761669158936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 250/815 [05:24<12:06,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.4078755378723145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 300/815 [06:28<10:52,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.7002103328704834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 350/815 [07:31<09:52,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.648704767227173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 400/815 [08:35<08:47,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.350796699523926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 450/815 [09:39<07:50,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.170565128326416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 500/815 [10:44<06:50,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.067795515060425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 550/815 [11:49<05:44,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 2.997896671295166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 600/815 [12:55<04:39,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.297666311264038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 650/815 [14:00<03:35,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.2895662784576416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 700/815 [15:05<02:30,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.3113598823547363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 750/815 [16:11<01:25,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.55607271194458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 800/815 [17:17<00:19,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.7031962871551514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [17:37<00:00,  1.30s/it]\n",
      "  0%|          | 1/246 [00:00<00:39,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  3.516152452398663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:38<00:00,  6.47it/s]\n",
      "  0%|          | 0/815 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss:  5.265978390608376\n",
      "Epoch:  4\n",
      "Batch loss: 2.805488109588623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 50/815 [01:03<16:20,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 2.314272403717041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 100/815 [02:07<15:27,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.094869613647461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 150/815 [03:13<14:33,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.16937255859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 200/815 [04:18<13:27,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.155062437057495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 250/815 [05:22<12:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.0544891357421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 300/815 [06:26<10:57,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 2.672611713409424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 350/815 [07:30<10:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 2.8221964836120605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 400/815 [08:35<08:50,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 2.795255422592163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 450/815 [09:39<07:52,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.1434857845306396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 500/815 [10:44<06:47,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.3067824840545654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 550/815 [11:48<05:40,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.1697263717651367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 600/815 [12:52<04:38,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 4.947449207305908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 650/815 [13:57<03:36,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.018280267715454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 700/815 [15:05<02:32,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 2.806668281555176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 750/815 [16:10<01:24,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 3.343299150466919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 800/815 [17:16<00:19,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch loss: 2.863215208053589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815/815 [17:35<00:00,  1.30s/it]\n",
      "  0%|          | 1/246 [00:00<00:39,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss:  3.132227631141803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:37<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Loss:  5.448638367459057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train 3 more epochs\n",
    "EPOCHS = 5\n",
    "best = 100000\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch: ', epoch)\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_dl, optimizer, loss_func)\n",
    "    print('Train Loss: ', train_loss)\n",
    "    \n",
    "    valid_loss = evaluate(model, valid_dl, loss_func)\n",
    "    print('Valid Loss: ', valid_loss)\n",
    "    \n",
    "    if valid_loss < best:\n",
    "        best = valid_loss\n",
    "        torch.save(model.state_dict(),  '../model/seq2seq_v2.pt')\n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train 3 more epochs\n",
    "# EPOCHS = 10\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     print('Epoch: ', epoch)\n",
    "    \n",
    "#     train_loss = train_one_epoch(model, train_dl, optimizer, loss_func)\n",
    "#     print('Train Loss: ', train_loss)\n",
    "    \n",
    "#     valid_loss = evaluate(model, valid_dl, loss_func)\n",
    "#     print('Valid Loss: ', valid_loss)\n",
    "    \n",
    "#     if valid_loss < best:\n",
    "#         best = valid_loss\n",
    "#         torch.save(model.state_dict(),  '../model/seq2seq_v2.pt')\n",
    "#     scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.3415e-07,  1.8757e-08, -1.0000e+00, -7.6159e-01,  2.7992e-12,\n",
       "          -3.5686e-05,  8.0224e-15, -1.5713e-10, -1.4366e-13,  3.3050e-13,\n",
       "           2.0661e-21,  1.0000e+00, -1.2542e-10, -4.9077e-11, -9.7051e-05,\n",
       "           1.3208e-20,  7.0467e-07,  1.1476e-12, -1.8057e-11,  8.1142e-15,\n",
       "          -3.8975e-02, -1.4302e-16, -1.0386e-09, -2.6230e-12,  7.6159e-01,\n",
       "          -2.6330e-23, -1.2532e-02, -5.2528e-04, -1.2949e-07,  2.4892e-08,\n",
       "           6.0026e-07, -1.1196e-10,  1.5296e-10, -5.0617e-09,  2.4082e-09,\n",
       "          -3.3455e-08, -1.0477e-16,  4.9381e-16, -9.8111e-22,  1.8580e-14,\n",
       "          -4.9357e-11,  1.0770e-11,  4.9214e-10,  9.3780e-16, -6.4904e-04,\n",
       "           1.0489e-06,  5.5468e-14,  1.2570e-05, -5.2065e-02, -1.0022e-04,\n",
       "          -1.2523e-10, -3.3691e-08,  1.9675e-05, -1.4091e-15,  1.4231e-01,\n",
       "           1.4667e-12,  5.1739e-10, -5.8571e-08, -3.2723e-04,  1.1033e-10,\n",
       "          -3.1379e-28, -2.8651e-10, -1.4404e-19, -9.0455e-08, -7.8566e-11,\n",
       "           1.3765e-10,  4.9446e-08,  2.5476e-09, -3.1349e-08, -2.8717e-14,\n",
       "           4.1009e-12,  9.0636e-10,  1.3285e-11,  4.4793e-11, -5.4704e-17,\n",
       "          -1.9342e-10, -7.6961e-11, -5.8884e-17,  9.2462e-03, -1.0238e-11,\n",
       "          -2.8134e-13,  7.6159e-01,  2.5199e-09, -1.2039e-12, -1.7211e-16,\n",
       "          -1.4748e-07, -8.5063e-12,  4.6814e-16,  1.0759e-16, -1.0000e+00,\n",
       "          -2.6427e-26, -1.0770e-02,  3.1461e-09,  2.5775e-08,  3.7092e-26,\n",
       "           1.6739e-11,  2.0317e-25, -4.5702e-12,  8.0046e-14, -6.0396e-11,\n",
       "           4.7022e-25, -4.7724e-07, -7.5799e-11, -8.4636e-10,  2.0097e-13,\n",
       "           1.0125e-06,  1.7511e-10,  9.7946e-11,  1.1944e-14, -1.0000e+00,\n",
       "           1.0000e+00, -9.7485e-08,  9.7563e-09, -1.0528e-11, -1.0930e-03,\n",
       "           1.8838e-08,  2.3630e-07,  2.1257e-13, -2.5075e-15, -5.2711e-07,\n",
       "           1.3443e-29, -1.3560e-03,  1.3562e-06, -9.9305e-19,  1.0000e+00,\n",
       "           2.6614e-07,  4.3066e-09,  2.4873e-14, -1.4642e-09,  2.3889e-22,\n",
       "           4.3710e-14, -4.6720e-02,  5.6218e-09,  1.5116e-11,  5.6153e-09,\n",
       "           1.0000e+00, -4.6661e-09,  9.7760e-22,  8.9010e-14, -1.6127e-11,\n",
       "          -2.2074e-12,  4.4158e-27, -7.6159e-01, -3.8015e-02,  6.4763e-20,\n",
       "          -6.4404e-08,  9.1023e-09, -1.8285e-13,  9.1019e-12, -1.2197e-08,\n",
       "           2.7767e-10,  6.7147e-10, -9.1421e-09, -5.5355e-08,  3.4110e-11,\n",
       "           2.4689e-12, -2.0813e-07,  2.4052e-14,  2.0371e-09, -8.0117e-24,\n",
       "           1.5338e-21, -4.6145e-03,  1.0000e+00,  6.5855e-11,  6.0851e-11,\n",
       "          -1.2440e-07,  6.6149e-21, -5.2121e-10,  1.0000e+00,  1.6491e-08,\n",
       "          -5.8150e-11, -4.8320e-11,  1.2325e-08, -4.2827e-09,  1.1008e-13,\n",
       "          -1.0000e+00,  5.8404e-11, -3.8083e-10, -1.0000e+00,  6.7080e-11,\n",
       "           2.0297e-10,  1.0270e-01, -3.3564e-13,  1.8523e-15, -1.0000e+00,\n",
       "          -9.4786e-11, -7.0984e-06, -4.0065e-10,  5.5447e-08,  1.0000e+00,\n",
       "           3.0686e-11,  7.9642e-07,  7.0685e-12, -9.5438e-14, -8.2457e-05,\n",
       "          -7.6198e-07, -1.1899e-10, -3.6804e-17,  1.3207e-14, -7.7605e-14,\n",
       "          -9.9476e-01,  5.0469e-06,  4.0656e-16,  3.4020e-15,  1.9151e-06,\n",
       "          -4.0434e-26,  3.2205e-08, -4.3674e-09, -7.6144e-01, -7.3121e-14,\n",
       "          -1.3824e-07,  6.1466e-08, -7.3538e-26,  6.6500e-15, -3.3248e-07,\n",
       "           1.0000e+00,  3.6650e-13, -2.0898e-08,  4.9180e-12,  1.9031e-07,\n",
       "           5.0448e-12, -2.1450e-16, -7.6159e-01,  1.0000e+00,  3.7287e-17,\n",
       "           4.8356e-12,  1.0000e+00, -5.2864e-07, -4.7354e-11,  2.0782e-13,\n",
       "          -1.4318e-08, -9.3999e-11,  2.2857e-04, -1.3566e-10, -3.2166e-03,\n",
       "          -1.9981e-05,  1.4835e-03, -2.7394e-10,  9.2278e-12,  1.7502e-12,\n",
       "          -3.6867e-17, -1.1449e-10,  2.4320e-11, -6.1318e-17, -7.6149e-01,\n",
       "           5.2561e-09, -6.1599e-15, -1.0065e-01,  2.3076e-10,  3.1643e-15,\n",
       "          -5.5232e-01, -1.4257e-06, -2.2189e-13, -2.4821e-06, -5.9745e-14,\n",
       "           1.3974e-04, -5.1463e-22,  7.6159e-01, -2.4480e-03, -3.6327e-11,\n",
       "          -1.4107e-10,  4.0540e-10, -3.3417e-14, -1.3700e-10,  7.6159e-01,\n",
       "          -1.6639e-23,  5.8423e-27,  4.4754e-03, -1.0000e+00, -2.2025e-12,\n",
       "          -1.4419e-13, -7.6159e-01, -1.0093e-07, -4.1858e-17, -4.5342e-14,\n",
       "           1.7498e-10,  2.6384e-11, -4.4152e-09, -4.8146e-15,  2.5242e-06,\n",
       "          -1.9673e-06,  1.0000e+00, -3.9875e-08, -1.5969e-04,  1.5440e-09,\n",
       "          -2.7324e-10,  1.4477e-12, -1.8652e-16,  1.0548e-13, -7.5916e-11,\n",
       "           3.6071e-10,  5.2838e-22, -6.3665e-14, -3.3777e-13, -9.8407e-14,\n",
       "           7.6159e-01,  1.3633e-11,  2.8580e-10,  9.2228e-16, -1.4475e-05,\n",
       "          -1.0058e-09, -5.8477e-07, -6.5089e-09,  4.7209e-09,  2.1132e-16,\n",
       "          -5.9605e-09,  1.4449e-11,  4.6788e-09, -9.3408e-04, -4.8944e-09,\n",
       "          -3.9525e-09, -4.7983e-11, -2.3320e-27,  2.1443e-09,  1.1054e-05,\n",
       "          -1.2043e-11,  2.3734e-08,  3.0749e-12, -2.0329e-09, -4.6275e-02,\n",
       "           1.2237e-06,  1.8574e-10, -1.2889e-17,  7.3204e-15, -7.6159e-01,\n",
       "           1.0000e+00, -8.4847e-13, -7.6159e-01,  4.5644e-12, -4.2921e-11,\n",
       "           4.0110e-08, -6.0500e-07, -1.3565e-08,  2.9219e-09,  4.7153e-11,\n",
       "           1.0000e+00,  6.1012e-14, -9.0220e-01, -1.4923e-16,  6.8048e-10,\n",
       "           3.0781e-17, -1.0078e-13, -1.2629e-09,  2.7254e-12, -8.8841e-11,\n",
       "           9.5877e-17,  3.2370e-10,  1.1602e-10,  5.3071e-11,  2.5113e-10,\n",
       "          -1.0145e-09,  1.9289e-12, -2.2038e-18,  2.2842e-08,  3.9374e-09,\n",
       "          -2.9938e-08,  1.4297e-30, -1.6779e-18, -3.4992e-11,  1.2163e-09,\n",
       "           8.7093e-08,  2.6112e-12,  3.6172e-12, -1.0756e-09,  3.4260e-09,\n",
       "          -7.5577e-09, -5.0272e-10,  8.0846e-11,  4.5662e-14,  1.6713e-09,\n",
       "          -3.0490e-05,  1.3711e-13, -5.4495e-10,  3.5678e-10,  2.5634e-11,\n",
       "           4.7728e-11,  1.5807e-08,  3.8139e-10,  2.0863e-11,  1.1218e-09,\n",
       "           1.1221e-01,  6.5520e-26,  7.6177e-10,  4.2122e-11, -1.5374e-03,\n",
       "          -2.8512e-11,  3.7352e-02,  1.0000e+00, -1.0000e+00, -1.0765e-06,\n",
       "           1.0555e-15,  3.1016e-11, -1.2957e-09, -1.1898e-07,  1.0932e-10,\n",
       "          -9.6253e-09, -2.0374e-24,  8.0792e-07,  1.1558e-09,  9.9283e-07,\n",
       "          -1.1455e-13,  7.5371e-09, -2.3519e-09, -1.3080e-10,  1.6785e-06,\n",
       "          -7.4822e-13,  7.0594e-15,  1.0701e-12,  6.1955e-15,  3.2217e-06,\n",
       "          -2.2987e-06, -3.0029e-20,  1.3897e-10,  9.9999e-01, -6.0170e-16,\n",
       "           4.1747e-04,  1.4579e-12, -6.2663e-16,  4.6652e-11,  6.8469e-10,\n",
       "           1.0785e-07, -3.0025e-15,  1.0000e+00,  1.1956e-20, -1.0000e+00,\n",
       "           6.1595e-07, -9.6382e-05, -3.9603e-11,  7.6159e-01, -2.7042e-28,\n",
       "           9.4996e-13, -3.4837e-09, -1.4055e-06, -2.9560e-06, -2.3441e-08,\n",
       "           1.7434e-01,  3.1450e-07,  6.9858e-10,  2.2650e-06,  7.5632e-01,\n",
       "          -8.5240e-25,  2.4636e-10, -1.6547e-16, -4.5360e-11,  1.3631e-18,\n",
       "           1.7080e-14,  5.2297e-08,  2.6665e-11, -2.1053e-05,  6.0264e-14,\n",
       "          -5.2385e-15, -1.1067e-07, -1.5459e-12, -9.6062e-12,  1.6440e-10,\n",
       "          -1.9503e-13,  1.7698e-09,  7.6160e-01,  1.4645e-05, -1.9994e-12,\n",
       "          -5.4941e-20, -1.9083e-11, -3.0622e-08, -1.2029e-07,  1.4261e-04,\n",
       "           3.0314e-09,  4.9384e-08, -1.3734e-05,  1.0000e+00,  1.4927e-08,\n",
       "          -5.2514e-17,  2.5863e-10, -1.0000e+00,  2.6630e-09,  6.2905e-03,\n",
       "           3.6822e-15,  2.3792e-13,  9.6616e-20,  7.6159e-01, -4.2835e-10,\n",
       "           4.8274e-13, -1.8301e-15,  2.7109e-12, -4.2892e-24, -2.3211e-08,\n",
       "           3.8126e-09, -1.3649e-06,  3.7600e-12, -4.2794e-13, -3.1722e-25,\n",
       "          -5.5280e-20,  4.8895e-08,  1.4968e-09, -5.0621e-09, -7.8561e-14,\n",
       "          -3.6016e-15, -2.9086e-12, -1.0316e-03,  4.0109e-10, -2.1743e-02,\n",
       "          -1.6683e-01,  3.1676e-33, -3.1692e-19,  7.8820e-06, -9.3719e-13,\n",
       "          -1.8513e-09,  1.1684e-16, -3.9326e-09,  1.3238e-07, -1.0000e+00,\n",
       "           3.3547e-11, -4.6864e-14,  1.0101e-20, -6.4408e-20,  1.1804e-07,\n",
       "           5.1590e-07,  1.2512e-09, -2.5929e-09, -3.6057e-05,  4.7752e-15,\n",
       "          -8.1391e-07, -2.8379e-08,  5.3851e-11, -1.0000e+00, -4.3296e-08,\n",
       "          -1.3523e-11, -1.9586e-07, -4.6160e-10, -4.8485e-15, -1.5846e-08,\n",
       "          -2.9453e-24, -7.8629e-10, -5.8177e-06, -1.5854e-11,  4.1974e-07,\n",
       "           2.8464e-12,  4.6945e-08,  9.1518e-09, -1.4985e-16,  7.0716e-02,\n",
       "           6.3613e-08,  1.0000e+00, -3.9775e-10,  7.6159e-01,  1.3115e-35,\n",
       "          -1.3815e-09,  2.8125e-08,  1.4548e-02, -1.7705e-12,  1.2035e-15,\n",
       "          -1.6492e-02, -5.3461e-09,  5.6090e-16, -4.9492e-09, -2.1196e-04,\n",
       "           1.3934e-11,  3.9153e-07, -1.8111e-11, -9.8962e-05,  8.9453e-06,\n",
       "           2.9542e-14,  3.3710e-08,  9.0423e-10,  2.4779e-27, -4.8405e-21,\n",
       "           1.0000e+00, -7.2679e-07, -1.0000e+00,  1.6877e-11,  1.2025e-07,\n",
       "           1.8433e-18, -6.0712e-11, -7.4386e-11,  2.2427e-09, -4.6506e-10,\n",
       "           1.2461e-09,  2.6077e-05,  1.0074e-11,  5.0857e-11, -2.6322e-09,\n",
       "           2.5371e-15,  2.9549e-11,  1.9869e-15,  2.4526e-12, -1.0000e+00,\n",
       "          -1.5903e-11, -3.0295e-04, -4.4557e-16,  2.0546e-11,  4.8306e-22,\n",
       "           2.9260e-11, -9.3240e-21, -2.0892e-10,  3.1496e-09,  1.9104e-16,\n",
       "          -9.0668e-12, -2.1620e-10,  4.5663e-15,  1.0000e+00, -1.8464e-12,\n",
       "           1.2578e-07, -6.4666e-13,  1.5219e-10,  3.8444e-08,  1.4972e-17,\n",
       "          -1.9575e-10, -1.8429e-13,  1.2215e-14,  1.5118e-08, -6.5224e-08,\n",
       "           3.5603e-08, -2.4907e-10, -6.6299e-08, -4.0116e-09,  1.0257e-11,\n",
       "           2.7645e-08, -7.6159e-01, -3.1893e-11,  4.6584e-06, -1.0786e-11,\n",
       "          -1.0752e-10,  1.4273e-11, -1.2721e-09, -5.5312e-10,  1.1148e-02,\n",
       "          -9.7147e-15,  8.5599e-11,  4.4218e-09, -9.5257e-31, -9.8891e-09,\n",
       "          -1.0011e-05,  2.8926e-08,  6.4256e-16,  1.9018e-13, -1.9039e-22,\n",
       "           1.5072e-05,  1.0647e-08,  1.2581e-12, -1.2566e-09,  7.3255e-07,\n",
       "          -1.7681e-10, -9.9940e-10,  6.7118e-18,  6.5256e-09, -2.4323e-15,\n",
       "           1.3004e-08,  8.3823e-10, -7.9870e-10, -4.4808e-14,  2.8769e-11,\n",
       "           1.4666e-12, -4.6944e-10,  1.3147e-08,  5.2438e-20,  4.9397e-11,\n",
       "          -1.0000e+00, -3.2699e-09,  6.1717e-11, -1.6918e-09, -2.7133e-12,\n",
       "           3.1078e-10, -1.4057e-10, -1.0000e+00, -3.0822e-06,  4.9731e-08,\n",
       "           1.2374e-12,  2.1570e-08,  2.8260e-18, -3.4944e-08, -8.2411e-04,\n",
       "          -4.0212e-12, -3.5951e-02,  9.6121e-18, -2.7090e-06,  1.0838e-08,\n",
       "           8.4866e-09, -3.2158e-03,  1.3993e-03,  7.0009e-21, -7.1436e-12,\n",
       "           6.2904e-09, -7.6159e-01,  1.5544e-12, -8.1295e-09,  2.5074e-12,\n",
       "          -2.9300e-04, -2.6335e-29,  1.5366e-12, -3.7797e-10,  2.3093e-11,\n",
       "          -1.2398e-12,  8.9382e-11,  5.4210e-12,  3.8848e-09, -6.7352e-13,\n",
       "          -7.7398e-11,  2.8760e-35,  2.0964e-21,  1.5266e-14, -8.7174e-08,\n",
       "          -4.7285e-10,  2.6316e-14,  1.0349e-06, -4.9397e-04, -2.0679e-02,\n",
       "          -3.7752e-17, -4.0779e-08, -6.3816e-13,  2.4583e-09,  3.1125e-18,\n",
       "           1.0707e-07,  2.2753e-10, -8.8847e-07,  5.4379e-13, -5.1292e-03,\n",
       "          -4.0126e-15,  1.7044e-09,  8.9347e-09, -1.3989e-09,  2.7211e-10,\n",
       "           4.1499e-03, -8.2397e-01, -3.0989e-02, -4.2240e-11, -6.9282e-07,\n",
       "           1.9060e-14,  2.1969e-12,  3.5942e-09,  1.0000e+00, -1.8007e-08,\n",
       "           1.3574e-14,  1.7919e-10, -1.2696e-16,  5.6128e-11,  1.7713e-07,\n",
       "           2.0617e-14,  1.8149e-02, -1.6247e-07, -2.7812e-10, -1.0601e-09,\n",
       "           1.3909e-09,  2.1682e-08,  2.7390e-07, -1.1030e-14,  5.7847e-08,\n",
       "           2.4637e-03,  7.0279e-10, -4.0922e-12,  1.5467e-11,  3.6512e-07,\n",
       "           6.0392e-09, -1.3410e-10, -1.8193e-10, -1.8911e-06,  1.3519e-10,\n",
       "           1.0196e-21,  1.2184e-11,  6.2724e-12,  1.2503e-14,  1.8700e-07,\n",
       "          -6.2604e-12,  1.0000e+00,  4.4132e-09, -6.5667e-10, -1.8251e-09,\n",
       "           3.2559e-17,  1.3010e-09,  6.8135e-20,  2.6176e-10,  7.6159e-01,\n",
       "           6.7349e-25,  7.6159e-01, -5.1687e-10, -2.1046e-11,  2.1768e-18,\n",
       "          -7.4948e-02,  1.6387e-09, -2.5176e-09, -3.3847e-13, -4.1844e-13,\n",
       "          -9.3688e-10, -3.6494e-10,  1.0000e+00, -6.6247e-07, -2.4310e-07,\n",
       "           5.6255e-25,  4.0146e-13, -2.8625e-19,  1.5358e-07, -1.1666e-07,\n",
       "           1.2818e-08,  3.4116e-09, -9.8157e-12, -9.8172e-10, -6.0956e-19,\n",
       "          -3.7073e-24,  6.1957e-12,  1.0106e-16,  2.8816e-11,  2.2423e-24]]])"
      ]
     },
     "execution_count": 1058,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    context = model.encoder(test_x.unsqueeze(0))\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_seq(model, x, start_token, seq_length):\n",
    "    with torch.no_grad():\n",
    "        word_input = torch.tensor(word2idx[start_token]).unsqueeze(0)\n",
    "        context = model.encoder(x.unsqueeze(0))\n",
    "        hidden = context\n",
    "        outputs = [start_token]\n",
    "        ## generate a sequence!\n",
    "        for i in range(seq_length):\n",
    "            output, hidden = model.decoder(word_input, context, hidden)\n",
    "            word = output.argmax(1)\n",
    "            outputs.append(idx2word[word.item()])\n",
    "            word_input = word\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 2048])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x, test_y = next(iterator)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'fore',\n",
       " 'arm',\n",
       " 'of',\n",
       " 'water',\n",
       " 'polo',\n",
       " 'is',\n",
       " 'long',\n",
       " 'according',\n",
       " 'to',\n",
       " 'ted',\n",
       " '<END>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>',\n",
       " '<PAD>']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2word[word.item()] for word in test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'a',\n",
       " 'man',\n",
       " 'is',\n",
       " 'singing',\n",
       " 'a',\n",
       " 'song',\n",
       " '<END>',\n",
       " 'sweet',\n",
       " 'voice',\n",
       " '<END>',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'a',\n",
       " 'living',\n",
       " '<UNK>']"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_seq(model, test_x,  '<START>', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
