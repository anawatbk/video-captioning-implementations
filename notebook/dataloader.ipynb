{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path configuration\n",
    "LABELS_PATH = '../data/train_val_annotation/train_val_videodatainfo.json'\n",
    "DATA_PATH = '../data/train_val_features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pickle import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON file\n",
    "f = open (LABELS_PATH, \"r\")\n",
    "  # Reading from file\n",
    "data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 9,\n",
       " 'url': 'https://www.youtube.com/watch?v=9lZi22qLlEo',\n",
       " 'video_id': 'video0',\n",
       " 'start time': 137.72,\n",
       " 'end time': 149.44,\n",
       " 'split': 'train',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['videos'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomly select sentence\n",
    "#label_df = pd.DataFrame(data['sentences'])\n",
    "#label_final_df = label_df.groupby('video_id')['sen_id'].unique().apply(lambda x: x[np.random.randint(0,20)]).to_frame().reset_index()\n",
    "#label_final_df['video_id'].nunique()\n",
    "#label_final_df = label_final_df.join(label_df[['sen_id', 'caption']].set_index('sen_id'), on='sen_id')\n",
    "#label_final_df.to_csv('../data/label_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_final_df = pd.read_csv('../data/label_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create embedding matrix from google news word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en_core_web_sm', disable = ['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "# embedding\n",
    "import gensim.downloader\n",
    "\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "glove_emb = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = label_final_df['caption'].tolist()#.astype('unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = Counter()\n",
    "try:\n",
    "    for doc in nlp.pipe(all_sent):\n",
    "        for word in doc:\n",
    "            #print(word)\n",
    "            wc[str(word)] += 1\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(doc,'\\nword:', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding matrix\n",
    "# initialization\n",
    "EMBEDDING_SIZE = 300\n",
    "embedding = np.zeros((len(wc)+4, 300)) # +4 for start, end, unk, padding\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "\n",
    "word2idx['<PAD>'] = 0\n",
    "idx2word[0] = '<PAD>'\n",
    "embedding[0] = np.random.rand(300)*2 - 1\n",
    "\n",
    "word2idx['<START>'] = 1\n",
    "idx2word[1] = '<START>'\n",
    "embedding[1] = np.random.rand(300)*2 - 1\n",
    "\n",
    "word2idx['<END>'] = 2\n",
    "idx2word[2] = '<END>'\n",
    "embedding[2] = np.random.rand(300)*2 - 1\n",
    "\n",
    "word2idx['<UNK>'] = 3\n",
    "idx2word[3] = '<UNK>'\n",
    "embedding[3] = np.random.rand(300)*2 - 1\n",
    "\n",
    "count = 0\n",
    "for word, _ in wc.most_common():\n",
    "    wid = len(word2idx)\n",
    "    word2idx[word] = wid\n",
    "    idx2word[wid] = word\n",
    "    if word in glove_emb:\n",
    "        embedding[wid] = glove_emb.get_vector(word)\n",
    "    else:\n",
    "        embedding[wid] = np.random.rand(300)*2 - 1 # random initialisation (-1, 1)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 words are not in google news werd2vec\n"
     ]
    }
   ],
   "source": [
    "print(f'{count} words are not in google news werd2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Dataset Class for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSRVTT(Dataset):\n",
    "    def __init__(self, df, word2idx, DATA_PATH):\n",
    "        super(MSRVTT, self).__init__()\n",
    "        self.df = df\n",
    "        self.path = DATA_PATH\n",
    "        self.word2idx = word2idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        vid = row['video_id']\n",
    "        filename = self.path + f'{vid}-feature.pt5'\n",
    "        x = torch.load(filename)\n",
    "        y = [self.word2idx.get(word, self.word2idx['<UNK>']) for word in row['caption'].split(' ')]\n",
    "        #true_sentence = row['caption']\n",
    "        return x, torch.tensor(y).long()#, true_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MSRVTT(label_final_df, word2idx, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1810, 0.3634, 0.6611,  ..., 0.3846, 0.6012, 0.1157],\n",
       "        [0.0812, 0.3774, 0.7720,  ..., 0.6932, 0.7245, 0.2265],\n",
       "        [0.0763, 0.4366, 0.8833,  ..., 0.4071, 1.0229, 0.1807],\n",
       "        ...,\n",
       "        [0.1818, 0.6062, 0.4046,  ..., 0.4644, 0.5192, 0.4749],\n",
       "        [0.3772, 0.6626, 0.1883,  ..., 0.4252, 0.4500, 0.3894],\n",
       "        [0.4353, 0.6842, 0.9035,  ..., 0.5593, 1.5382, 0.2510]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  4,   8,   5, 106,  63,   4, 124])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6519 491\n"
     ]
    }
   ],
   "source": [
    "# split train/test\n",
    "train_proportion = 0.93\n",
    "train_size = int(train_proportion * len(ds))\n",
    "validation_size = len(ds) - train_size\n",
    "print(train_size, validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, validation_ds = random_split(ds, [train_size, validation_size])\n",
    "# dataloaders\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "validation_dl = DataLoader(validation_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
