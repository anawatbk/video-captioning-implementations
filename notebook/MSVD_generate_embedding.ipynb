{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import dump, load\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bank/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "import gensim.downloader\n",
    "\n",
    "glove_emb = gensim.downloader.load('word2vec-google-news-300')\n",
    "nlp = spacy.load('en_core_web_sm', disable = ['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PATH = '../data/MSVD_label_final.csv'\n",
    "label_final_df = pd.read_csv(LABELS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sent = label_final_df['caption'].tolist()#.astype('unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = Counter()\n",
    "try:\n",
    "    for doc in nlp.pipe(all_sent):\n",
    "        for word in doc:\n",
    "            #print(word)\n",
    "            wc[str(word)] += 1\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(doc,'\\nword:', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4624"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num unique words: 6157<br>\n",
    "only >5 occurence words: 1259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_N = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "EMBEDDING_SIZE = 300\n",
    "embedding = np.zeros((len(wc.most_common(top_N))+4, 300)) # +4 for start, end, unk, padding\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "\n",
    "word2idx['<PAD>'] = 0\n",
    "idx2word[0] = '<PAD>'\n",
    "embedding[0] = np.random.normal(0, 0.2, 300)\n",
    "\n",
    "word2idx['<START>'] = 1\n",
    "idx2word[1] = '<START>'\n",
    "embedding[1] = np.random.normal(0, 0.2, 300)\n",
    "\n",
    "word2idx['<END>'] = 2\n",
    "idx2word[2] = '<END>'\n",
    "embedding[2] = np.random.normal(0, 0.2, 300)\n",
    "\n",
    "word2idx['<UNK>'] = 3\n",
    "idx2word[3] = '<UNK>'\n",
    "embedding[3] = np.random.normal(0, 0.2, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for word, _ in wc.most_common(top_N):\n",
    "    wid = len(word2idx)\n",
    "    word2idx[word] = wid\n",
    "    idx2word[wid] = word\n",
    "    if word in glove_emb:\n",
    "        embedding[wid] = glove_emb.get_vector(word)\n",
    "    else:\n",
    "        embedding[wid] = np.random.normal(0, 0.1, 300) # random initialisation (-1, 1)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 words are not in google news word2vec\n"
     ]
    }
   ],
   "source": [
    "print(f'{count} words are not in google news word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings matrix\n",
    "np.save('../model/MSVD_embedding.npy', embedding)\n",
    "import pickle\n",
    "with open(\"../model/MSVD_word2idx.pkl\",\"wb\") as f:\n",
    "    pickle.dump(word2idx, f)\n",
    "with open(\"../model/MSVD_idx2word.pkl\",\"wb\") as f:\n",
    "    pickle.dump(idx2word, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
